# Машинное обучение с учителем
## Описание

### Цели недели

С этой недели мы начинаем знакомиться с методами и алгоритмами машинного обучения. Наше знакомство начнется с одного из наиболее распространенных подходов – обучения с учителем, при котором обучение происходит на основе набора данных, содержащих правильные ответы или метки классов.

### После освоения темы:
- Вы познакомитесь с терминологией, используемой в машинном обучении
- Узнаете виды линейных моделей обучения, метрики измерения качества линейных моделей
- Узнаете базовые сведения об ансамблевых моделях и сравните производительность ансамблевых моделей
- Сможете строить модели линейной и логистической регрессии с использованием библиотек Python
- Сможете рассчитывать метрику качества линейной и логистической регрессии
- Сможете строить ансамблевые модели — решающее дерево, случайный лес, градиентный бустинг

### План занятия
- Введение
- Линейные модели
- Измерение качества модели
- Ансамблевые модели

### Используемые термины

__Машинное обучение (Machine Learning)__ — подход к анализу данных, который позволяет компьютерным системам изучать и делать прогнозы на основе данных без явного программирования.

__Обучение с учителем (supervised learning)__ — алгоритм получает размеченные данные. Его цель — научиться предсказывать правильный ответ на новых данных.

__Обучение без учителя (unsupervised learning)__ — алгоритм получает неразмеченные данные. Его цель — найти скрытые закономерности в данных.

__Глубокое обучение (Deep Learning)__ — это подход к машинному обучению, использующий нейронные сети с большим количеством скрытых слоев.

__Обучение с подкреплением (Reinforcement Learning)__ — метод, при котором модель обучается на основе награды или штрафа за каждое принятое решение.

__Полунадзорное обучение (Semi-Supervised Learning)__ — метод, который используется в случаях, когда у нас есть небольшое количество маркированных данных и большое количество немаркированных данных.

__Активное обучение (Active Learning)__ — метод, при котором модель активно запрашивает у эксперта метки для новых данных, чтобы улучшить свою точность.

__Функционал качества__ — метрика, которая оценивает, насколько хорошо модель соответствует данным обучения.

__Среднеквадратичная ошибка (MSE)__ — средняя величина квадрата отклонения прогнозируемых значений от фактических значений целевой переменной.

__Средняя абсолютная ошибка (MAE)__ — среднее значение модуля отклонения прогнозируемых значений от фактических значений целевой переменной.

__Градиент__ — направление наискорейшего роста функции.

__Градиентный спуск__ — это метод оптимизации, который используется для минимизации функционала ошибки в линейных моделях.

__Логистическая регрессия__ — метод машинного обучения, который используется для бинарной классификации, то есть разделения объектов на два класса.

__Матрица ошибок (Confusion matrix)__ — таблица, которая показывает количество верных и неверных прогнозов модели бинарной классификации.

__Кросс-валидация (cross-validation)__ — метод оценки качества модели машинного обучения на основе повторного выбора и разбиения данных на тренировочный и тестовый наборы.

__Регуляризация__ — метод, используемый для снижения переобучения моделей машинного обучения путем добавления дополнительных ограничений на коэффициенты модели.

__Ансамблевые модели__ — модели в машинном обучении, которые объединяют несколько моделей сразу, чтобы улучшить качество прогнозирования.

__Бэггинг (Bagging)__ — метод, который заключается в использовании нескольких независимых моделей, каждая из которых обучается на своей подвыборке данных. После этого ответы каждой модели усредняются.

__Бустинг (Boosting)__ — метод, который заключается в последовательном обучении нескольких слабых моделей, каждая из которых учится на подмножестве данных, где веса объектов учитывают ошибки предыдущих моделей.

__Решающее дерево__ — структура, используемая в машинном обучении для прогнозирования значения целевой переменной.

__Максимальная глубина дерева (max_depth)__ — гиперпараметр, который ограничивает максимальное количество узлов в дереве.

__Минимальное количество объектов для разделения (min_samples_split)__ — гиперпараметр, который определяет минимальное количество объектов, необходимых для того, чтобы узел был разделен на две ветви.

__Случайный лес__ — алгоритм машинного обучения, который строит множество решающих деревьев и усредняет их прогнозы, чтобы получить более точный прогноз.

__Градиентный бустинг__ — это метод машинного обучения, который позволяет строить ансамбль из простых моделей, обычно деревьев решений.

### Итоги занятия

1. __Машинное обучение (ML)__ — подход к анализу данных, который позволяет компьютерным системам изучать и делать прогнозы на основе данных без явного программирования

__Основные виды машинного обучения__:
- Обучение с учителем
- Обучение без учителя
- Глубокое обучение
- Обучение с подкреплением
- Полунадзорное обучение

2. Линейная регрессия используется для прогнозирования значений целевой переменной на основе независимых переменных. Модель строится на основе гипотезы о линейной зависимости между целевой переменной и независимыми переменными. Ее цель — минимизация ошибки модели путем нахождения оптимальных значений коэффициентов. Для оценки качества модели используются функционалы потерь, такие как среднеквадратичная ошибка и средняя абсолютная ошибка


3. Чтобы минимизировать ошибку, в линейных моделях используют метод градиентного спуска. Метод работает путем итеративного изменения вектора весов в направлении, обратном градиенту функции ошибки


4. Логистическая регрессия применяется к задачам с двумя классами. Для преобразования линейной комбинации признаков в вероятность принадлежности к классу используется функция сигмоиды. Функция потерь (log loss) используется для оценки качества логистической регрессии и представляет собой логарифмическую функцию правдоподобия


5. Качество моделей можно измерить с помощью метрик. Основные метрики качества для линейной регрессии — __MSE, RMSE, MAE, R2__.  Для оценки качества классификации логистической регрессии используется матрица ошибок


6. Переобучение — проблема, когда модель слишком точно подгоняется под обучающие данные и не работает хорошо на тестовых данных. Для борьбы с переобучением существуют __методы регуляризации (L1 и L2)__ и __кросс-валидация__


7. Ансамблевые модели объединяют несколько моделей для улучшения прогнозирования

__Бэггинг__ – метод, использующий несколько независимых моделей, ответы которых усредняются

__Бустинг__ — метод, последовательно обучающий слабые модели с учетом ошибок предыдущих моделей

8. __Решающие деревья__ — основа ансамблевых моделей, используются для прогнозирования значений целевой переменной. Гиперпараметры решающих деревьев, такие как максимальная глубина и минимальное количество объектов, влияют на их эффективность и склонность к переобучению. __Случайный лес__ — алгоритм, который строит множество решающих деревьев и усредняет их прогнозы для более точного прогнозирования


9. Градиентный бустинг строит ансамбль из простых моделей, обычно деревьев решений. Метод основан на идее последовательного обучения моделей, где каждая следующая модель исправляет ошибки предыдущей
---

### В результате выполнения заданий вы сможете:

- Строить модели линейной и логистической регрессии с использованием библиотек Python
- Рассчитывать метрика качества линейной и логистической регрессии
- Строить ансамблевые модели — решающее дерево, случайный лес, градиентный бустинг